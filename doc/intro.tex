\section{Introduction}

This paper is about some of the lies we tell when we talk about programs.

An example lie (or to be more formal, a ``leaky abstraction'') is the order
of reads and writes in a program. We pretend that these happen in the
order specified by the program text, for example
we think of the program
\(( \aLoc\GETS0 \SEMI \aLoc\GETS1 \SEMI \bLoc\GETS2 )\)
as having three sequentially ordered write events:
\[\begin{tikzpicture}[node distance=1em]
  \event{wx0}{\DW{\aLoc}{0}}{}
  \event{wx1}{\DW{\aLoc}{1}}{right=of wx0}
  \event{wy2}{\DW{\bLoc}{2}}{right=of wx1}
  \po{wx0}{wx1}
  \po{wx1}{wy2}
\end{tikzpicture}\]
However, due to optimizations in hardware or compilers, instructions
may be reordered, resulting in executions where the accesses of
$\aLoc$ and $\bLoc$ are independent, and the hardware
or compiler is free to reorder them:
\[\begin{tikzpicture}[node distance=1em]
  \event{wx0}{\DW{\aLoc}{0}}{}
  \event{wx1}{\DW{\aLoc}{1}}{right=of wx0}
  \event{wy2}{\DW{\bLoc}{2}}{right=of wx1}
  \po{wx0}{wx1}
\end{tikzpicture}\]
Instruction reordering optimizations are not problematic as long
as they are not visible to user code, that is if programs
are sequentially consistent. Unfortunately, multi-threaded
programs can often observe reorderings. For example
running the above writing thread concurrently with
an observing thread \((\IF(\bLoc)\THEN \cLoc\GETS\aLoc \FI)\)
can result in a sequentially inconsistent execution
(where we highlight the matching write for each read):
\[\begin{tikzpicture}[node distance=1em]
  \node(th1){Writing thread:};
  \event{wx0}{\DW{\aLoc}{0}}{right=of th1}
  \event{wx1}{\DW{\aLoc}{1}}{right=of wx0}
  \event{wy2}{\DW{\bLoc}{2}}{right=of wx1}
  \po{wx0}{wx1}
  \node(th2)[below=2.5ex of th1]{Observing thread:};
  \event{ry2}{\DR{\bLoc}{2}}{below=of wx0}
  \event{rx0}{\DR{\aLoc}{0}}{below=of wx1}
  \event{wz0}{\DW{\cLoc}{0}}{below=of wy2}
  \po{ry2}{rx0}
  \po{rx0}{wz0}
  \rf{wx0}{rx0}
  \rf[out=210,in=35]{wy2}{ry2}
\end{tikzpicture}\]

This leaky abstraction has resulted in a literature
of \emph{relaxed memory models}~\cite{Manson:2005:JMM:1047659.1040336,SevcikThesis,DBLP:conf/esop/JagadeesanPR10,DBLP:journals/toplas/Lochbihler13,DBLP:conf/esop/BattyMNPS15,DBLP:conf/lics/JeffreyR16,Kang-promising-2017},
which try to state precisely the memory guarantees
a compiler is expected to provide, without requiring the use of
expensive memory barriers to ensure sequential consistency.

Relaxed memory is an example of how simple models can become
complex. Instruction reordering was originally intended to be
visible only to the microarchitecture or compiler,
not to the architecture or user code.
Reordering optimizations are so important to the performance
of modern systems that hardware and programming language designers
have now accepted the complexity of relaxed memory models as the price
that has to be paid for acceptable performance.

This paper looks at another leaky abstraction:
\emph{speculative evaluation}. This is similar to reordering,
in that it is an optimization that was intended to be visible only to the microarchitecture,
but the arrival of Spectre~\cite{DBLP:journals/corr/abs-1801-01203}
shows that not only is speculation visible, it has serious
security implications.

The simplest example of speculative evaluation
is branch prediction. The expected observable behavior of
a conditional such as
\(( \IF(\aLoc) \THEN \bLoc\GETS1 \ELSE \cLoc\GETS1 \FI )\)
is that just one branch will execute, for example:
\[\begin{tikzpicture}[node distance=1em]
  \event{rx0}{\DR{\aLoc}{0}}{}
  \event{wz1}{\DW{\cLoc}{1}}{right=of rx0}
  \po{rx0}{wz1}
\end{tikzpicture}\]
To improve instruction throughput, hardware will often evaluate
branches speculatively, and roll back any failed speculations. For example,
hardware might incorrectly speculate that $\aLoc$ is
nonzero, speculatively execute a write to $\bLoc$,
but then roll it back and execute a write to $\cLoc$:
\[\begin{tikzpicture}[node distance=1em]
  \event{rx0}{\DR{\aLoc}{0}}{}
  \nonevent{nwy1}{\DW{\bLoc}{1}}{right=of rx0}
  \event{wz1}{\DW{\cLoc}{1}}{right=of nwy1}
  \po{rx0}{nwy1}
  \po[out=30,in=150]{rx0}{wz1}
\end{tikzpicture}\]
Speculation is intended only to be visible at the microarchitectural
level, but as Spectre shows, this abstraction is leaky, and in a way
that allows side-channel attacks to be mounted.

Instruction reordering and speculative evaluation are similar leaky abstractions.
Both were intended originally not to
be visible to user code, but both abstractions have leaked.
This opens some possible areas of investigation:
\begin{itemize}

\item \emph{Using ideas from relaxed memory for speculation}.  There is a
  significant literature showing how to build models of relaxed memory, for
  use in validating compilers, or proving correctness of programs.  Less
  formally, they provide programmers with a way to visualize and communicate
  the behavior of their systems.  Inspired by these models, we give a
  compositional model of program execution that includes speculation
  (\S\ref{sec:model} and \S\ref{sec:semantics}) and show how it can be used
  to model known attacks (\S\ref{sec:examples}) on branch prediction
  \cite{DBLP:journals/corr/abs-1801-01203} and transactional memory
  \cite{ChongSW18,DBLP:conf/uss/DisselkoenKPT17}.

\item \emph{Mounting attacks against speculation on relaxed memory}.
  Spectre shows how a leaky abstraction allows for the construction of
  side-channels which bypass dynamic security checks. Since defences
  against buffer overflows are often dynamic checks, these attacks
  allow all memory in a process to be read.  Inspired by these
  attacks, we show how to mount information flow attacks against
  compiler optimizations, both against the model (\S\ref{sec:compiler})
  and against existing compilers (\S\ref{sec:experiments}).
  Fortunately, we were only able to mount the attacks against
  ahead-of-time compilers (where optimizations require secrets
  to be known at compile-time) and not just-in-time compilers
  (which can optimize based on run-time secrets).
  With the addition of shared-memory concurrency
  to JavaScript~\cite[\S24.2]{ecma-262}, the attacks described in this paper might
  become feasible. We hope that compiler designers become as
  aware of information flow attacks against optimizations as their
  hardware designing colleagues.

\end{itemize}
Readers who wish to focus on the impact of the model can skip to \S\ref{sec:examples}
on first reading, referring to prior sections as needed.

\section{Related work}

Information flow provides a formal
foundation for end-to-end security.  Informally, a program is secure
if there is no observable dependency of low-security outputs on high-security inputs.
The precise formalization of this intuitive idea has been the topic of
extensive research \cite{Sabelfeld:2006:LIS:2312191.2314769}, encompassing a variety of language
features such as non-determinism~\cite{Wittbold1990InformationFI},
concurrency~\cite{Smith:1998:SIF:268946.268975}, reactivity~\cite{O'Neill:2006:ISI:1155442.1155677}, and
probability~\cite{Gray:1992:TMF:2699806.2699811}. The static and dynamic enforcement
of these definitions in general purpose languages~\cite{myers-popl99} has % also
% been studied extensively and has
influenced language design and implementation.

A key parameter in defining information flow is the \emph{observational power} of the attacker model. Whereas the classical
input-output behavior is often an adequate foundation,
it has long been known~\cite{Lampson:1973:NCP:362375.362389,Biswas:2017:STC:3058791.3023872} that side-channels that leak
information arise from other observables such as execution time and
power consumption.
Recently, the Spectre family of attacks~\cite{DBLP:journals/corr/abs-1801-01203} has
shown that branch prediction, in conjunction with cache-timing side-channels,
allows adversaries to bypass dynamic security checks.

\citet{Chien:2018} argues that Spectre-like attacks ``extend the functional
specification of the architecture to include its detailed performance'' and
thus ``making strong assurances of application security on a computing system
requires detailed performance information.''
This approach has been pursued in the information flow literature, by
enriching language semantics with observables such as execution time and  power consumption
\cite{Zhang:2012:LCM:2345156.2254078,hyperflow}.   This approach
has also been pursued to develop model-checking techniques for Spectre-like
attacks \cite{DBLP:conf/micro/TrippelLM18}.  Like our work,
\cite{DBLP:conf/micro/TrippelLM18} recognizes the role played by adapting
techniques from relaxed memory.

In this paper, we adopt the opposite approach, attempting to understand
Spectre-like attacks as \emph{abstractly} as possible and thus to reveal the
``essence'' of Spectre.  We develop a novel model of speculative
evaluation and show that it is sufficient to both capture known attacks and
predict new attacks.  Our model is defined at the \emph{language} level,
rather than the hardware level; thus, we do not model micro-architectural
details such as caches or timing.

Relaxed memory models
\cite{SparcV9,Manson:2005:JMM:1047659.1040336,Boehm:2008:FCC:1375581.1375591,DBLP:conf/popl/ZhaoNMZ12,
  Jagadeesan:2010:GOS:2175486.2175503,Kang-promising-2017} allow
speculative execution to varying degrees. Relaxed execution is known to
affect the validity of information flow analyses
\cite{6957104,Vaughan:2012:SIF}.
In these models, a valid execution is defined
with reference to other possible executions of the program. These
models are not, however, designed for modeling Spectre-style attacks
on speculation. For example all of these models will consider the
straight-line code:
\[
  r\GETS x\SEMI s\GETS\SEC \SEMI
  a[r]\GETS 1
\]
to be the same as the conditional code:
\[\begin{array}{ll}
  r\GETS x\SEMI s\GETS\SEC \SEMI \\[\jot]
  \IF(r\EQ s) \THEN a[s]\GETS 1 \ELSE a[r]\GETS 1 \FI
\end{array}\]
and indeed an optimizing compiler might choose to rewrite
either of these programs to be the other.

An attacker can mount a Spectre-style attack on the
conditional code, for example by setting $x$ to be~$0$,
flushing the cache,
executing the program, then using timing effects to
determine if $a[1]$ is in the cache. If it is, then $\SEC$
must have been~$1$. This attack is not possible against
the straight-line code, and so any model trying to
capture Spectre must distinguish them.

Most definitions of non-interference will say that in both
programs, there is no observable dependency of the low-security
outputs ($a$) on the high-security inputs ($\SEC$) and so both programs
are safe.
  The only existing models of
non-interference which capture this information flow are ones such
as~\cite{Zhang:2012:LCM:2345156.2254078} which model
micro-architectural features such as caching and timing.

In our model, the straight-line and conditional programs are not equated, since the conditional code has the execution:
\[\begin{tikzpicture}[node distance=1em]
  \event{rx0}{\DR{\aLoc}{0}}{}
  \event{rs1}{\DR{\SEC}{1}}{below=of rx0}
  \event{wa01}{\DW{a[0]}{1}}{right=3em of rx0}
  \nonevent{wa11}{\DW{a[1]}{1}}{below=of wa01}
  \po{rx0}{wa01}
  \po{rs1}{wa01}
  \po{rx0}{wa11}
  \po{rs1}{wa11}
\end{tikzpicture}\]
which is not matched in the straight-line code.
Indeed, from an information-flow perspective,
this refined treatment of dependencies in conditionals identifies a novel
distinguishing feature of our model, namely that the traditional conditional
is a self-composition operator in the sense
of~\cite{Barthe:2004:SIF:1009380.1009669}.

Static analyses such as the Smith-Volpano type
system~\cite{Smith:1998:SIF:268946.268975} will reject the conditional
program, due to $a[s]\GETS 1$, in which a low-security assignment depends on
a high-security variable.  We show how to circumvent such analyses in
\S\ref{sec:spectre}.



\endinput

%%% Old intro follows.

Information flow provides a formal
foundation for end-to-end security.  Informally, a program is secure
if there is no observable dependency of low-security outputs on high-security inputs.
The precise formalization of this intuitive idea has been the topic of
extensive research \cite{Sabelfeld:2006:LIS:2312191.2314769}, encompassing a variety of language
features such as non-determinism~\cite{Wittbold1990InformationFI},
concurrency~\cite{Smith:1998:SIF:268946.268975}, reactivity~\cite{O'Neill:2006:ISI:1155442.1155677}, and
probability~\cite{Gray:1992:TMF:2699806.2699811}. The static and dynamic enforcement
of these definitions in general purpose languages~\cite{myers-popl99} has % also
% been studied extensively and has
influenced language design and implementation.

A key parameter in defining information flow is the \emph{observational power} of the attacker model. Whereas the classical
input-output behavior is often an adequate foundation,
it has long been known~\cite{Lampson:1973:NCP:362375.362389,Biswas:2017:STC:3058791.3023872} that side-channels that leak
information arise from other observables such as execution time and
power consumption.
Recently, the Spectre family of attacks~\cite{DBLP:journals/corr/abs-1801-01203} has
shown that branch prediction, in conjunction with cache-timing side-channels,
allows adversaries to bypass dynamic security checks.

\citet{Chien:2018} argues that Spectre-like attacks ``extend the functional
specification of the architecture to include its detailed performance'' and
thus ``making strong assurances of application security on a computing system
requires detailed performance information.''
This approach has been pursued in the information flow literature, by
enriching language semantics with observables such as execution time and  power consumption
\cite{Zhang:2012:LCM:2345156.2254078,hyperflow}.

In this paper, we adopt the opposite approach, attempting to understand
Spectre-like attacks as \emph{abstractly} as possible and thus to reveal the
``essence'' of Spectre.  We develop a novel model of \emph{speculative
  evaluation} and show that it is sufficient to both capture known attacks and
predict new attacks.  Our model is defined at the \emph{language} level,
rather than the hardware level; thus, we do not model micro-architectural
details such as caches or timing, as in
\cite{Zhang:2012:LCM:2345156.2254078,hyperflow}.
% We try to give as
% simple a model as possible, while still capturing shared-memory concurrency
% and speculation.


There are several sources of speculative evaluation in modern computer
systems, intended to improve performance without affecting the observable
behavior of the program: Failed speculations are meant to be
undetectable. Yet, Spectre-like attacks show that failed speculations are not
always undetectable.  Our model provides a unifying mechanism to understand
these sources of speculation.  Because failed speculations are part of the
model, it is easily enriched with operators to detect operations that occur
in failed speculations.
% In the spirit of \citet{Chien:2018}, our model ``extends the functional
% specification of the programming language to include its detailed performance''.
% so that failed speculation does not affect the input-output behavior
% of the program, but may affect other observable behavior, opening an opportunity
% for side-channels:
\begin{itemize}
\item Relaxed memory models
  \cite{SparcV9,Manson:2005:JMM:1047659.1040336,Boehm:2008:FCC:1375581.1375591,DBLP:conf/popl/ZhaoNMZ12}
  allow speculative execution to varying degrees. Relaxed execution
  is known to affect the validity of information flow analyses
  \cite{6957104,Vaughan:2012:SIF}.  More troubling, relaxed memory models
  allow for the observation of control and data dependencies. This creates an
  opportunity for information flows caused by optimizing compilers, whose
  behavior is driven by dependency analysis.  Our basic model captures this
  dependency analysis.
  %% For example,
  %% $(\IF(\aReg)\THEN \aLoc\GETS1 \ELSE \aLoc\GETS1 \FI)$ can be optimized to
  %% $(\aLoc\GETS1)$, whereas  %% $(\IF(\aReg)\THEN \aLoc\GETS1 \ELSE \aLoc\GETS2 \FI)$ cannot be so
  %% optimized.
\item Pipelined micro-architectures use \emph{branch prediction}
  to speculatively execute the result of
  a conditional jump or indirect jump instruction.
  Spectre \cite{DBLP:journals/corr/abs-1801-01203} exploits
  cache timing to detect the operations performed in a mispredicted branch
  before being flushed from the pipeline.  We capture Spectre by enriching
  our language with a single operation that allows one to test whether a
  location has been touched. %, even in a failed speculation.
  %% This means,
  %% for example, that a single execution of
  %% $(\IF(\aExp)\THEN \aCmd \ELSE \bCmd \FI)$ may depend on both $\aCmd$ and
  %% $\bCmd$.  This differs from the standard semantics of the conditional, in
  %% which executions of $\aCmd$ and $\bCmd$ are disjoint.
\item Some microprocessors support transactional
  memory~\cite{ChongSW18}, where aborted transactions are meant to be
  unobservable.  \textsc{Prime+Abort}
  \cite{DBLP:conf/uss/DisselkoenKPT17} uses cache timing to detect the
  operations performed in an aborted transaction.  We capture \textsc{Prime+Abort} by enriching
  our language with transactions that abort when a location used by the
  transaction is touched outside the transaction.
\end{itemize}

%% This line of research was initiated by~\citet{Zhang:2012:LCM:2345156.2254078}.
%% Whereas they explore static annotations to address side channels in the context of hardware description languages, we explore a model of programs
%% that captures enough detail to reveal and analyze the presence of side
%% channels revealed by speculative execution.
%

Our model is based on \emph{partially ordered multisets}~\cite{GISCHER1988199,Plotkin:1997:TSP:266557.266600}
(``pomsets''), whose labels are given by read and write actions. These can be
visualized as a graph where the edges indicate dependencies, for example
$(\aReg\GETS\aLoc\SEMI \bLoc\GETS1\SEMI \cLoc\GETS\aReg+1)$
has an execution modeled by the pomset:
\[\begin{tikzpicture}[node distance=1em]
  \event{rx1}{\DR{\aLoc}{1}}{}
  \event{wy1}{\DW{\bLoc}{1}}{right=of rx1}
  \event{wz2}{\DW{\cLoc}{2}}{right=of wy1}
  \po[out=25,in=155]{rx1}{wz2}
\end{tikzpicture}\]
The edge from $(\DR{\aLoc}{1})$ to $(\DW{\cLoc}{2})$ indicates a
data dependency. Since there is no dependency between
$(\DW{\bLoc}{1})$ and $(\DW{\cLoc}{2})$, the write actions may
take place in either order.  Such reorderings may arise in
hardware (for example, caching) or in the compiler (for example,
instruction reordering).

The novel aspect of the model is that events have
\emph{preconditions} which may be false. These are used in giving the
semantics of conditionals and transactions, modeling failed branch
prediction and aborted transactions. For example the program
$(\IF(\aLoc)\THEN \bLoc\GETS1\SEMI\cLoc\GETS1 \ELSE \bLoc\GETS2\SEMI\cLoc\GETS1\FI)$
has an execution:
\[\begin{tikzpicture}[node distance=1em]
  \event{rx1}{\DR{\aLoc}{1}}{}
  \event{wy1}{\DW{\bLoc}{1}}{right=of rx1}
  \nonevent{wy2}{\DW{\bLoc}{2}}{below=of wy1}
  \event{wz1}{\DW{\cLoc}{1}}{right=of wy1}
  \po{rx1}{wy1}
  \po{rx1}{wy2}
\end{tikzpicture}\]
The edges from $(\DR{\aLoc}{1})$ to $(\DW{\bLoc}{1})$ and
$(\DW{\bLoc}{2})$ indicate control dependencies. The presence of
a crossed out $(\DW{\bLoc}{2})$ indicates an event with an unsatisfiable precondition,
modeling an unsuccessful speculation.
Since the $(\DW{\cLoc}{1})$ action is performed on both branches of the conditional,
there is no control dependency from $(\DR{\aLoc}{1})$.  Indeed, from an information-flow perspective,
this refined treatment of dependencies in conditionals identifies a novel distinguishing feature of our model, namely that the traditional conditional is a self-composition operator in the sense of~\cite{Barthe:2004:SIF:1009380.1009669}.

There do exist models of programs which include speculation, notably
the Java Memory Model~\cite{Manson:2005:JMM:1047659.1040336}, and the
generative~\cite{Jagadeesan:2010:GOS:2175486.2175503} and
promising~\cite{Kang-promising-2017} operational semantics for
relaxed memory.  In all of these models a valid execution is defined
with reference to other possible executions of the program. These
models are not, however, designed for modeling Spectre-style attacks
on speculation. For example all of these models will consider the
straight-line code:
\[
  r\GETS x\SEMI s\GETS\SEC \SEMI
  a[r]\GETS 1
\]
to be the same as the conditional code:
\[\begin{array}{ll}
  r\GETS x\SEMI s\GETS\SEC \SEMI \\[\jot]
  \IF(r\EQ s) \THEN a[s]\GETS 1 \ELSE a[r]\GETS 1 \FI
\end{array}\]
and indeed an optimizing compiler might choose to rewrite
either of these programs to be the other.

An attacker can mount a Spectre-style attack on the
conditional code, for example by setting $x$ to be~$0$,
flushing the cache,
executing the program, then using timing effects to
determine if $a[1]$ is in the cache. If it is, then $\SEC$
must have been~$1$. This attack is not possible against
the straight-line code, and so any model trying to
capture Spectre must distinguish them.

Most definitions of non-interference will say that in both
programs, there is no observable dependency of the low-security
outputs ($a$) on the high-security inputs ($\SEC$) and so both programs
are safe.
  The only existing models of
non-interference which capture this information flow are ones such
as~\cite{Zhang:2012:LCM:2345156.2254078} which model
micro-architectural features such as caching and timing.

In our model, the straight-line and conditional programs are not equated, since the conditional code has the execution:
\[\begin{tikzpicture}[node distance=1em]
  \event{rx0}{\DR{\aLoc}{0}}{}
  \event{rs1}{\DR{\SEC}{1}}{below=of rx0}
  \event{wa01}{\DW{a[0]}{1}}{right=3em of rx0}
  \nonevent{wa11}{\DW{a[1]}{1}}{below=of wa01}
  \po{rx0}{wa01}
  \po{rs1}{wa01}
  \po{rx0}{wa11}
  \po{rs1}{wa11}
\end{tikzpicture}\]
which is not matched in the straight-line code.

Static analyses such as the Smith-Volpano type
system~\cite{Smith:1998:SIF:268946.268975} will reject the conditional
program, due to $a[s]\GETS 1$, in which a low-security assignment depends on
a high-security variable.  We show how to circumvent such analyses in
\S\ref{sec:spectre}.


The model in this paper leads to new attacks on optimizing
compilers~(\S\ref{sec:info-flow-attack} and~\S\ref{sec:dse}) which
were discovered as a consequence of building the model. A natural
question is whether these attacks are an artifact of the model, or if
they can be mounted in practice? We mounted the attacks on gcc and
clang, where they succeeded in leaking a $\SEC$ as long as the secret
was a constant known at compile time. By itself this is not too
worrying, since secrets are not normally static constants. If the same
attacks could be mounted against Just-In-Time~(JIT) compilers, this
is potentially significant, as secrets are often known at JIT-compile
time.

Fortunately, our attempts to mount the attacks against SpiderMonkey,
V8 and HotSpot did not succeed. We speculate that this is because
JIT compilers do not perform as agressive optimizations as
ahead-of-time compilers, and not because of mitigations against
information flows. With the addition of shared-memory concurrency
to JavaScript~\cite[\S24.2]{ecma-262}, the attacks described in this paper might
become feasible. We hope that compiler designers become as
aware of information flow attacks against optimizations as their
hardware designing colleagues.

The novel contributions of this paper are:
\begin{itemize}

\item a compositional model of program execution that includes speculation
  (\S\ref{sec:model} and \S\ref{sec:semantics}),

\item examples showing how the model can be applied,
  including existing information flow attacks on
  hardware and transactional memory, and new attacks on optimizing compilers (\S\ref{sec:examples}), and

\item experimental evidence about how practical it is to mount
  the new class of attacks (\S\ref{sec:experiments}).

\end{itemize}
Readers who wish to focus on the impact of the model can skip to \S\ref{sec:examples}
on first reading, referring to prior sections as needed.
