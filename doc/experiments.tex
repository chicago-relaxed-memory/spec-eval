\section{Experiments}
\label{sec:experiments}

One theme of this paper is that optimizations not typically part of formal
abstractions can result in information flow leaks.
This is typified by the Spectre attack, which leverages speculative execution,
a hardware optimization.
\S\ref{sec:info-flow-attack} and~\S\ref{sec:dse} presented other attacks
along the same line, which leverage compiler optimizations.
These attacks also, unlike Spectre, do not rely on timing side channels, or
indeed timers of any kind, bypassing many common Spectre mitigations~\cite{???}.
%%%%% FuzzyFox, Chrome's and Firefox's restrictions on precise timers, etc.

In this section we present implementations of the attacks described
in~\S\ref{sec:info-flow-attack} and~\S\ref{sec:dse}, in both cases
exploiting compiler optimizations to construct an information flow attack.
\ignore{
The attacker model (detailed in~\S\ref{subsec:attacker-model})
is currently unrealistic, as we attack C compilers rather than scripting
languages, and we require the secret to be a compile-time constant which
the compiler can optimize on.
This renders these attacks proof-of-concepts rather than
immediately exploitable vulnerabilities.
However, we believe their novelty may lead to
interesting discussion, and with much more development, these attacks may
evolve into genuine threats against targets such as JIT compilers.
}
We demonstrate the efficacy of our proof-of-concept attacks against
the {\CLANG} and {\GCC} C compilers.
All of our experiments are performed on a \todo{describe machine} with
{\CLANG} version \todo{clang version} and {\GCC} version \todo{gcc
version}.

\subsection{Attacker model}
\label{subsec:attacker-model}

In our attacker model, we assume that there is a {\SEC} hardcoded into an
application; for instance, {\SEC} may be an API key.
This {\SEC} is known at compile time, but may not be
accessed except behind a security check.
Since the attacker is running with low security privileges,
the security check always fails,
so the attacker can only access {\SEC} in dead code.
\ignore{
The attacker has no capabilities other than writing and executing code --- in
particular the attacker may not disassemble the compiler or libraries to learn
the {\SEC} directly; may not examine the internal state of the compiler;
may not access timers of any kind; and may not leverage hardware side channels.
}
The attacker's goal is to learn the value of the {\SEC}.

As a hypothetical example, suppose there is a library which contains
a hardcoded {\SEC} such as an API or signing key, which cannot be accessed
directly, only through a function guarded by a security check:
\todo{change real code to match this}
\begin{verbatim}
  private static const uint SECRET = 0x1234;
  private static volatile uint securityLevel = 0;
  public uint get_secret() {
    if (securityLevel > 0) { return SECRET; }
    else { return 0; }
  }
\end{verbatim}
This is not necessarily a realistic attacker model,
since in most cases secrets are only known at run time rather than compile time,
which means that the attacks presented in this section
are more proof-of-concepts rather than immediately exploitable vulnerabilities.
However, the mechanisms we use are novel and could potentially be applied
in other contexts.
For instance, many real-world contexts allow untrusted or
third-party entities to write code in a scripting language which is then
compiled alongside and integrated into a larger application, often
using a just-in-time (JIT) compiler.
JavaScript code from third-party websites running in a browser is a common
example of this.
We give an attacker similar capabilities against a
compiler, except that we consider the simpler setting of using C code against a C
compiler.
One could imagine a similar attack using JavaScript against browser JIT
compilers, where the compiler may have access to interesting secrets such as the
browser's cookie store, and may be able to optimize based on those secrets.
We plan to explore JavaScript attacks of this type as future work.

\subsection{Load-store reordering attack}
\label{subsec:exp-rel-mem}

We begin by examining the attack in~\S\ref{sec:info-flow-attack} in
more detail, subject to the attacker model given above.
In particular, we show that by exploiting compiler optimizations which perform
load-store reordering, an attacker can learn the value of a compile-time
{\SEC} despite only being allowed to use it inside dead code, that is,
code that can never be executed at runtime.
This attack was tested and works against {\GCC} version \todo{gcc version}.

The form of the attack presented in~\S\ref{sec:info-flow-attack} works in
theory, but in practice, just because a compiler is \emph{allowed} to perform a
load-store reordering doesn't mean that it \emph{will}.
We found that {\GCC} and {\CLANG} chose to read $y$ into a
register first (before writing to $x$), regardless of the value of
{\SEC}.
However, we did find a related pattern in which {\GCC} will emit a
different ordering of the read of $y$ and the write of $x$ depending
on the value of a {\SEC}:
\[\begin{array}[t]{@{}l}
  \VAR x\GETS0\SEMI \VAR y\GETS0\SEMI\\\quad
    y\GETS x
  \PAR\begin{array}[t]{@{}l}
    x\GETS 1\SEMI\\
    \IF(\CANREAD(\SEC))\THEN x\GETS\SEC\SEMI\FI\\
    \IF(y > 0)\THEN \RETURN 0
    \brELSE \RETURN 1\FI
\end{array}\end{array}\]
\ignore{
\begin{verbatim}
    x := 0; y := 0;
    (
      y := x;
    ) || (
      x := 1;
      if (canRead(SECRET)) { x := SECRET; }
      if (y) { return 0; }
      else { return 1; }
    )
\end{verbatim}
}

Figure~\ref{fig:lsr-asm} shows the assembly output of {\GCC} in the cases
where {\SEC} is 0 and 1 respectively.
In the case that {\SEC} is $1$, {\GCC} removes the \IF
statement entirely, and moves the read of $y$ above the write of $x$.
However, when {\SEC} is $0$, the \IF statement must remain
intact, and {\GCC} does not move the read of $y$.
This means that if {\SEC} is $1$, the second thread will always
read $y\EQ0$ and always return $1$.
However, if {\SEC} is $0$, it is possible that the first thread
may observe $x\EQ1$ and write $y\GETS1$ in time for the second thread
to observe $y\EQ1$ and thus return $0$.
In this way, we leverage compiler load-store reordering to learn the value of
a compile-time {\SEC}.

\begin{figure}
  \begin{tabular}[fragile]{p{3cm} | p{3cm}}
    \texttt{SECRET == 0} & \texttt{SECRET == 1} \\
\begin{verbatim}
  mov f(%rip), %eax
  mov $1, x(%rip)
  test %eax, %eax
  je label1
  mov %0, x(%rip)
label1:
  mov y(%rip), %eax
  test %eax, %eax
  sete %eax
  ret
\end{verbatim}
  &
\begin{verbatim}
  mov f(%rip), %eax
  mov y(%rip), %eax
  mov $1, x(%rip)
  test %eax, %eax
  sete %eax
  ret
\end{verbatim}
  \\
  \end{tabular}
  \caption{
    (Simplified) x86 assembly output from \texttt{gcc} for the main thread of
    the load-store reordering attack.
    In particular, note that the order between \texttt{mov \$1, x(\%rip)}
    and \texttt{mov y(\%rip), \%eax} is different in the two cases.
    The call to \texttt{canRead(SECRET)} has been inlined; we implemented
    \texttt{canRead(x)} as \texttt{return f;} where
    \texttt{volatile bool f = false;}.
    Thus, \texttt{gcc} preserves the read of \texttt{f} even when its value is
    unused, as in the case on the right.
  }
  \label{fig:lsr-asm}
\end{figure}

We extend this attack to leak a secret consisting of an arbitrary number
\verb|N| of bits.
To do this, we simply compile \verb|N| copies of the test function, each
performing a boolean test on a single bit of the secret.
The function used for reading the \verb|k|th bit is as follows (for
\verb|N <= 64|):
\[\begin{array}[t]{@{}l}
  \VAR x\GETS0\SEMI \VAR y\GETS0\SEMI\\\quad
    y\GETS x
  \PAR\begin{array}[t]{@{}l}
    x\GETS 1\SEMI\\
    \IF(\CANREAD(\SEC))\THEN x\GETS\texttt{(\SEC\, \& (1 << k)) ? 1 : 0}\SEMI\FI\\
    \IF(y > 0)\THEN \RETURN 0
    \brELSE \RETURN 1\FI
\end{array}\end{array}\]
\ignore{
\begin{verbatim}
    x := 0; y := 0;
    (
      y := x;
    ) || (
      x := 1;
      if (canRead(SECRET)) { x := (SECRET & (1 << k)) ? 1 : 0; }
      if (y) { return 0; }
      else { return 1; }
    )
\end{verbatim}
}
Following the same analysis as above, this function will always return $1$
if the appropriate bit of {\SEC} is $1$, but may return $0$ if
the appropriate bit of {\SEC} is $0$.
The extension of the attack to the general case with truly arbitrary \verb|N|
is straightforward; {\SEC} becomes an array of 64-bit values, and we use
\verb|k / 64| and \verb|1 << (k & 63)| as the array index and bitmask
respectively.

We make three additional tweaks to improve the reliability so that the attacker
can confidently infer the value of {\SEC} based on the observed return
values of the function.
First, rather than performing $y\GETS x$ only once in the first thread, we
perform $y\GETS x$ continuously in a loop.
This maximizes the probability that, once $x\GETS 1$ occurs in the second
thread, $y$ will be immediately assigned $1$ by the first thread
and the second thread will be able to read $y\EQ 1$.

Second, we wish to lengthen the timing window between $x\GETS 1$ and the
read of $y$ in the second thread (in the case where the appropriate bit of
{\SEC} is $0$ and the read of $y$ remains below $x\GETS 1$).
However, we wish to do this in a way that does not block the reordering of the
read of $y$ upwards in the case where the appropriate bit of {\SEC}
is $1$.
We do this by inserting many copies of the line
\begin{verbatim}
    if (canRead(SECRET)) { x := (SECRET & (1 << k)) ? 1 : 0; }
\end{verbatim}
instead of just one.
In the case where the appropriate bit of {\SEC} is $0$, this
results in many calls to $\CANREAD(\SEC)$ and many conditional jumps,
which in practice creates a timing window for the first thread to perform
$y\GETS x$.
However, in the case where the appropriate bit of {\SEC} is $1$,
all of these inserted lines can be removed just as a single copy could be.
In practice, we found that inserting too many copies of the line prevents
{\GCC} from reordering the read of $y$ above the write to $x$ as
desired; inserting $30$ copies was sufficient to create a timing window
while still allowing the desired reordering.

Finally, we redundantly execute the entire attack several times, noting the
return value of the function in each case.
We note that if \emph{any} of the redundant runs produces a return value of
$0$ for a particular bit position, we can be certain that the
corresponding bit of {\SEC} \emph{must} be $0$, as it implies the
read of $y$ was not reordered upwards in that particular function.
On the other hand, the more runs that produce a return value of $1$ for a
particular bit position, the more certain we can be that the read of $y$
was reordered above the $x\GETS 1$ assignment, and the appropriate bit of
{\SEC} is $1$.

\begin{figure}
  \small
  \begin{tabular}{ r | l | l | l }
    Redundancy & Bandwidth (bits/s) & Bitwise Acc & Per-run Acc \\ \hline
    1          & 3.17 million       & 90.13\%     & 0.0\%       \\
    2          & 1.62 million       & 96.77\%     & 0.7\%       \\
    3          & 1.07 million       & 98.84\%     & 3.9\%       \\
    4          & 812 thousand       & 99.55\%     & 13.5\%      \\
    5          & 652 thousand       & 99.83\%     & 34.0\%      \\
    7          & 466 thousand       & 99.97\%     & 71.8\%      \\
    10         & 322 thousand       & 99.998\%    & 96.6\%      \\
    15         & 216 thousand       & 100.00\%    & 100.0\%     \\
  \end{tabular}
  \caption{
    Performance results for the load-store reordering attack when leaking a
    2048-bit secret.
    `Redundancy' is the number of redundant runs performed for error
    correction; more redundant runs improves accuracy but reduces bandwidth.
    `Bandwidth' is the number of bits leaked per second after accounting for
    any error correction.
    `Bitwise Accuracy' is the percentage of bits that were correct, while
    `Per-run Accuracy' is the percentage of full 2048-bit secrets that were
    correct in all bit positions.
    \todo{Note: numbers are not final (collected on Craig's machine inside a
    VM), but give an idea of where we stand.}
  }
  \label{fig:load-store-perf}
\end{figure}

Figure~\ref{fig:load-store-perf} gives the performance results for this attack
against {\GCC} version \todo{ver}.
The attack can sustain hundreds of thousands of bits per second leaked with
near-perfect accuracy, or millions of bits per second with error rates of a
few percent.
This means that an attacker can leak a 2048-bit secret with near-perfect
accuracy in under $10$ ms.
Note that this bandwidth assumes that all copies of the attack function are
already compiled; the cost of compilation is not included here.

\subsection{Dead store elimination attack}
\label{subsec:exp-dse}

In this section we return to the attack in~\S\ref{sec:dse} based on
dead store elimination.
We show that in our attacker model (given in~\S\ref{subsec:attacker-model}),
the attacker is able to exploit dead
store elimination to again learn the value of a compile-time {\SEC}
despite only being allowed to use it inside dead code, that is, code that can
never be executed at runtime.
This attack is even more efficient than the attack on load-store reordering,
and further, we were able to demonstrate its effectiveness against both
{\GCC} and {\CLANG}.

We start from the simple form of the attack presented in~\S\ref{sec:dse},
and extend it to leak a secret consisting of an
arbitrary number \verb|N| of bits.
As we did in the load-store reordering attack, we again compile \verb|N| copies
of the test function, each performing a boolean test on a single bit of the
secret.
The function used for reading the \verb|k|th bit is as follows (for
\verb|N <= 64|):
\[\begin{array}[t]{@{}l}
  \VAR x\GETS0\SEMI\\\quad
    r\GETS x
  \PAR\begin{array}[t]{@{}l}
    x\GETS 1\SEMI\\
    \IF(\CANREAD(\SEC))\THEN \IF(\SEC\,\texttt{ \& (1 << k)}\NOTEQ0)\THEN x\GETS 2\FI
    \brELSE x\GETS 2\FI
\end{array}\end{array}\]
\ignore{
\begin{verbatim}
    (
      r := x;
    ) || (
      x := 1;
      if (canRead(SECRET)) {
        if (SECRET & (1 << k)) { x := 2; }
      } else {
        x := 2;
      }
    )
\end{verbatim}
}
Then, we test each function in turn, each time noting the value of $r$
observed by the `listening' thread.
If the appropriate bit of {\SEC} is 1, the $x\GETS 2$ assignment is
guaranteed to happen, so the compiler can eliminate the $x \GETS 1$
assignment as a dead store and we will observe $r\EQ 2$; however, if the
appropriate bit of {\SEC} is 0, the $x\GETS 1$ assignment cannot be
eliminated, and we will observe $r\EQ 1$ with some probability.
The extension of the attack to the general case with truly arbitrary \verb|N|
is straightforward and proceeds exactly as it did for the attack on
load-store reordering.

We make three additional tweaks to improve the reliability so that the attacker
can confidently infer the value of {\SEC} based on the observed values
of $r$.
These three tweaks strongly resemble the reliability tweaks we made to the
load-store reordering attack and differ only in a few details.

First, rather than simply observing $x$ with $r\GETS x$ in the
`listening' thread, we continuously load $x$ in a loop until a
nonzero value is observed --- i.e., we perform
$\DO{r\GETS x} \WHILE(r\EQ0)$.
\ignore{
\begin{verbatim}
    do {
      r := x;
    } while(r == 0);
\end{verbatim}
}
This remedies the case where $r\GETS x$ could observe a value of $x$
from `before' either of the two possible writes performed by the other thread.

Second, we insert additional time-consuming computation immediately following
the $x\GETS 1$ operation in the `main' thread.
This lengthens the timing window in which $x$ has the value $1$,
increasing the likelihood that the `listening' thread will be able to observe
$x\EQ 1$ (unless the $x\GETS 1$ write was eliminated, of course).
Inserting this computation can be done without interfering with the dead store
elimination process itself, so that the compiler will continue to eliminate
the $x\GETS 1$ write if and only if the appropriate bit of {\SEC}
was 1.
For {\GCC}, we have a fair amount of freedom with the time-consuming
computation --- for instance, we can use an arbitrarily long loop.
In fact, we can perform a further optimization by monitoring the value of the
variable $r$ (written to by the listening thread) and breaking out of the
loop early if we see that the listening thread has already observed $x\EQ 1$.
However, with {\CLANG}, we cannot use a loop at all --- the time-consuming
computation must be branch-free, and furthermore must not consist of too many
instructions.
This is because {\CLANG}'s dead store elimination pass operates only
within basic blocks, and uses a heuristic to stop scanning the basic block
early if it is too large.
Nonetheless, we find that even with these restrictions, we are able to
construct a reliable and fast attack against both {\CLANG} and {\GCC}.

Finally, we redundantly execute the entire attack several times, noting the
final value of $r$ (the first observed nonzero value of $x$) in each
case.
We note that if \emph{any} of the redundant runs produces $r\EQ 1$ for a
particular bit position, we can be certain that the corresponding bit of
{\SEC} \emph{must} be $0$, as it implies that the $x\GETS 1$ write
was not eliminated in that particular function.
On the other hand, the more runs that observe $r\EQ 2$ in a particular bit
position despite our other reliability-increasing measures taken above, the
more certain we can be that the $x\GETS 1$ write was eliminated in that
function, and the appropriate bit of {\SEC} is $1$.

\begin{figure}
  \small
  \begin{tabular}{ r | l | l | l }
    Redundancy & Bandwidth (bits/s) & Bitwise Acc & Per-run Acc \\ \hline
    1          & 1.40 million       & 99.92\%     & 66.8\%      \\
    2          & 702 thousand       & 99.999\%    & 97.5\%      \\
    3          & 470 thousand       & 99.99999\%  & 99.9\%       \\
    4          & 352 thousand       & 100.0\%     & 100.0\%      \\
  \end{tabular}
  \caption{
    Performance results for the dead store elimination attack on {\CLANG} when
    leaking a 2048-bit secret.
    Terms are the same as defined in the caption for Figure~\ref{fig:load-store-perf}.
    \todo{Note: numbers are not final (collected on Craig's Mac with Apple Clang),
    but give an idea of where we stand.}
  }
  \label{fig:clang-dse-perf}
\end{figure}

Performance results for the dead store elimination attack against {\CLANG}
are given in Figure~\ref{fig:clang-dse-perf}.
This attack is faster than the load-store reordering attack against {\GCC} for
any given desired accuracy.
\todo{however, compared to the load-store reordering attack we don't have an
even-faster-but-even-less-accurate setting.
This could be accomplished by reducing the amount of `time-consuming computation'
which for clang we have been holding constant near the max value clang will
tolerate.
Really, we could make this a 2D table like Figure~\ref{fig:gcc-dse-perf}, we'll
just have a strict maximum on how far to the right you can go.}

\begin{figure}
  \small
  \begin{tabular}{ r | c | c | c | c | c | c }
    Stall amount & 10 & 20 & 50 & 100 & 200 & 500 \\ \hline
    Redundancy 1 & \makecell{2.75 million\\97.13\%} &
                   \makecell{2.55 million\\99.72\%} &
                   \makecell{2.27 million\\99.98\%} &
                   \makecell{1.83 million\\99.99\%} &
                   \makecell{1.34 million\\99.99\%} &
                   \makecell{728 thousand\\99.99\%} \\ \hline
    Redundancy 2 & \makecell{1.40 million\\99.01\%} &
                   \makecell{1.30 million\\99.99\%} &
                   \makecell{1.14 million\\100.0\%} &
                   \makecell{902 thousand\\100.0\%} &
                   \makecell{663 thousand\\100.0\%} &
                   \makecell{382 thousand\\100.0\%} \\ \hline
    Redundancy 3 & \makecell{926 thousand\\99.44\%} &
                   \makecell{870 thousand\\100.0\%} &
                   \makecell{763 thousand\\100.0\%} &
                   \makecell{610 thousand\\100.0\%} &
                   \makecell{443 thousand\\100.0\%} &
                   \makecell{246 thousand\\100.0\%} \\ \hline
    Redundancy 4 & \makecell{694 thousand\\99.71\%} &
                   \makecell{645 thousand\\100.0\%} &
                   \makecell{571 thousand\\100.0\%} &
                   \makecell{451 thousand\\100.0\%} &
                   \makecell{330 thousand\\100.0\%} &
                   \makecell{186 thousand\\100.0\%} \\
  \end{tabular}
  \caption{
    Performance results for the dead store elimination attack on {\GCC} when
    leaking a 2048-bit secret.
    Rows give different values of `redundancy' (as defined in previous figures),
    while columns give amounts of stall time immediately following the
    $x\GETS 1$ write (as measured in loop iterations).
    Each table cell gives the leak bandwidth in bits/sec, followed by the
    bitwise accuracy.
    \todo{Note: numbers are not final (collected on Craig's machine inside a
    VM), but give an idea of where we stand.}
  }
  \label{fig:gcc-dse-perf}
\end{figure}

Figure~\ref{fig:gcc-dse-perf} shows the performance results for the dead
store elimination attack against {\GCC}.
Unlike the other attacks we've discussed, our implementation of this attack
has two important ``knobs'' which trade off reliability vs.\@ performance,
rather than only one.
First, we have the length of time which the writing thread attempts to
``stall'' immediately after the $x\GETS 1$ write (which is configurable in this
case because {\GCC} will perform the dead store elimination even with a loop
here).
Second, as in the other attacks, we have the number of entire redundant runs of
the attack that are performed before the attacker reaches her conclusion.
Increased reliability can be achieved by adjusting either of these knobs,
and they each have (different) effects on the overall performance of the
attack.
Although Redundancy 1 never reaches perfect accuracy (probably because of rare
catastrophic events like OS interrupts), once we move to Redundancy 2,
increasing the ``stall'' time is much more advantageous than further
redundancy.
Perfect accuracy (in our tests) can be achieved with a bandwidth of over 1.1
million bits per second at Redundancy 2, making this our most efficient and
accurate attack by a considerable margin.
In particular, this means that this attack can leak a 2048-bit cryptographic
key with perfect accuracy (in our tests) in under $2$ ms.
